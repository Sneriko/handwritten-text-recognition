{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd071f3d0049937cc818ce2f9b352ba946595cd1ac61856b9bde9007f94463dcc87",
   "display_name": "Python 3.8.5  ('.venv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "71f3d0049937cc818ce2f9b352ba946595cd1ac61856b9bde9007f94463dcc87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notebook to create symspell dict from Gotland namelist and use this dict to spell-correct predict-file of Gotland name model, and then evaluate the model after it's been spell-corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tool to metrics calculation through data and label (string and string).\n",
    " * Calculation from Optical Character Recognition (OCR) metrics with editdistance.\n",
    "\"\"\"\n",
    "\n",
    "import string\n",
    "import unicodedata\n",
    "import editdistance\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def ocr_metrics(predicts, ground_truth, norm_accentuation=False, norm_punctuation=False):\n",
    "    \"\"\"Calculate Character Error Rate (CER), Word Error Rate (WER) and Sequence Error Rate (SER)\"\"\"\n",
    "\n",
    "    if len(predicts) == 0 or len(ground_truth) == 0:\n",
    "        return (1, 1, 1)\n",
    "\n",
    "    cer, wer, ser = [], [], []\n",
    "\n",
    "    for (pd, gt) in zip(predicts, ground_truth):\n",
    "        pd, gt = pd.lower(), gt.lower()\n",
    "\n",
    "        if norm_accentuation:\n",
    "            pd = unicodedata.normalize(\"NFKD\", pd).encode(\"ASCII\", \"ignore\").decode(\"ASCII\")\n",
    "            gt = unicodedata.normalize(\"NFKD\", gt).encode(\"ASCII\", \"ignore\").decode(\"ASCII\")\n",
    "\n",
    "        if norm_punctuation:\n",
    "            pd = pd.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "            gt = gt.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "        pd_cer, gt_cer = list(pd), list(gt)\n",
    "        dist = editdistance.eval(pd_cer, gt_cer)\n",
    "        cer.append(dist / (max(len(pd_cer), len(gt_cer))))\n",
    "\n",
    "        pd_wer, gt_wer = pd.split(), gt.split()\n",
    "        dist = editdistance.eval(pd_wer, gt_wer)\n",
    "        wer.append(dist / (max(len(pd_wer), len(gt_wer))))\n",
    "\n",
    "        pd_ser, gt_ser = [pd], [gt]\n",
    "        dist = editdistance.eval(pd_ser, gt_ser)\n",
    "        ser.append(dist / (max(len(pd_ser), len(gt_ser))))\n",
    "\n",
    "    metrics = [cer, wer, ser]\n",
    "    metrics = np.mean(metrics, axis=1)\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/erik/Riksarkivet/Projects/handwritten-text-recognition/output/1930_census_name_gotland_original/flor/predict.txt', 'r') as f:\n",
    "    \n",
    "    lines = f.readlines()\n",
    "    \n",
    "    predicts = [x.replace('TE_P', '') for x in lines if x.startswith('TE_P')]\n",
    "    gts = [x.replace('TE_L', '') for x in lines if x.startswith('TE_L')]\n",
    "    \n",
    "    predicts_clean = []\n",
    "    gts_clean = []\n",
    "    \n",
    "    for pred in predicts:\n",
    "        index = 0\n",
    "        for i, char in enumerate(pred):\n",
    "            if char.isupper():\n",
    "                index = i\n",
    "                break\n",
    "        predicts_clean.append(pred[i:])\n",
    "\n",
    "    for gt in gts:\n",
    "        index = 0\n",
    "        for i, char in enumerate(gt):\n",
    "            if char.isupper():\n",
    "                index = i\n",
    "                break\n",
    "        gts_clean.append(gt[i:].strip())\n",
    "\n",
    "\n",
    "    assert len(gts_clean) == len(predicts_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('/home/erik/Riksarkivet/Projects/handwritten-text-recognition/data/namelist_gotland/namn_gotland.xlsx')\n",
    "df.fillna(np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/erik/Riksarkivet/Projects/handwritten-text-recognition/data/namelist_gotland/names_corpus.txt', 'w') as f:\n",
    "\n",
    "    for i in range(0, df.shape[0]):\n",
    "        \n",
    "        row = df.iloc[i]\n",
    "        name = str(row['name_propercase'])\n",
    "\n",
    "        freq = 0 \n",
    "        \n",
    "        if not np.isnan(row['lastnamn_tot']):\n",
    "            freq += int(row['lastnamn_tot'])\n",
    "\n",
    "        if not np.isnan(row['förnamn_man']):\n",
    "            freq += int(row['förnamn_man'])\n",
    "\n",
    "        if not np.isnan(row['förnamn_kvinna']):\n",
    "            freq += int(row['förnamn_kvinna'])\n",
    "        \n",
    "        f.write(name + '$' + str(freq) + '\\n')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "from symspellpy import SymSpell, Verbosity\n",
    "\n",
    "sym_spell = SymSpell(count_thre)\n",
    "dictionary_path = '/home/erik/Riksarkivet/Projects/handwritten-text-recognition/data/namelist_gotland/names_corpus.txt'\n",
    "sym_spell.load_dictionary(dictionary_path, 0, 1, separator=\"$\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Britta Anna Kristina\nBritta Anna Kristina\n"
     ]
    }
   ],
   "source": [
    "sc_predicts = []\n",
    "\n",
    "for pred in predicts_clean:\n",
    "\n",
    "    names = pred.split()\n",
    "\n",
    "    names_sc = []\n",
    "\n",
    "    for name in names:\n",
    "    \n",
    "        suggestions = sym_spell.lookup(name, Verbosity.CLOSEST, max_edit_distance=2)\n",
    "        if len(suggestions) > 0:\n",
    "            names_sc.append(suggestions[0].term)\n",
    "        else:\n",
    "            names_sc.append(name)\n",
    "\n",
    "    sc_predicts.append(' '.join(names_sc).strip())\n",
    "\n",
    "sc_predicts.pop(1218)\n",
    "gts_clean.pop(1218)\n",
    "\n",
    "assert sc_predicts[0] == gts_clean[0]\n",
    "\n",
    "print(sc_predicts[0])\n",
    "print(gts_clean[0])\n",
    "\n",
    "    #sc_predicts = [x for x in sc_predicts if x != '']\n",
    "    #gts_clean = [x for x in gts_clean if x != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Character Error Rate: 0.04963380\nWord Error Rate:      0.12659321\nSequence Error Rate:  0.27401894\n"
     ]
    }
   ],
   "source": [
    "evaluate = ocr_metrics(predicts=sc_predicts, ground_truth=gts_clean)\n",
    "\n",
    "e_corpus = \"\\n\".join([\n",
    "                f\"Character Error Rate: {evaluate[0]:.8f}\",\n",
    "                f\"Word Error Rate:      {evaluate[1]:.8f}\",\n",
    "                f\"Sequence Error Rate:  {evaluate[2]:.8f}\"\n",
    "])\n",
    "\n",
    "print(e_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}